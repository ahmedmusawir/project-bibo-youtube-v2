# Session Log: 2026-02-04

## Status: ✅ End-to-End Pipeline Complete

### Summary
Successfully completed migration from OpenAI/Anthropic to Google Cloud/Gemini stack. The entire video generation pipeline now runs on Google services only.

---

## What Works Now

### Complete Pipeline (Google Cloud Only)
1. **Transcription** - Google Cloud Speech-to-Text (long-running recognition)
2. **Summarization** - Google Gemini (`gemini-3-flash-preview`)
3. **Text-to-Speech** - Google Cloud TTS (Studio voices)
4. **Image Prompting** - Google Gemini
5. **Image Generation** - Vertex AI Imagen
6. **Metadata Generation** - Google Gemini (JSON output)
7. **Video Composition** - MoviePy 2.x

### Key Achievements
- ✅ No OpenAI dependencies (removed Whisper, TTS)
- ✅ No Anthropic dependencies (removed Claude)
- ✅ GCS integration for large audio files (>10MB)
- ✅ Automatic file size detection and routing
- ✅ 60-minute timeout for long video transcription
- ✅ All unit tests passing
- ✅ End-to-end video creation working

---

## Technical Details

### Authentication
- **ADC (Application Default Credentials)** via service account JSON
- Single credential file for all Google services
- Environment variable: `GOOGLE_APPLICATION_CREDENTIALS`

### File-Based Pipeline State
```
projects/<project_name>/
├── 0_transcript.txt       # Speech-to-Text output
├── 1_summary.txt          # Gemini summarization
├── 2_audio.mp3            # Google TTS output
├── 3_image_prompts.json   # Gemini image prompts
├── 4_metadata.json        # Gemini metadata (JSON)
├── 5_images/              # Vertex AI Imagen outputs
│   ├── image_0.png
│   ├── image_1.png
│   └── ...
└── 6_final_video.mp4      # MoviePy composition
```

### Environment Variables
```bash
# Required
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
GOOGLE_API_KEY=your-gemini-api-key
GOOGLE_STT_BUCKET=your-gcs-bucket-name

# Optional (with defaults)
GOOGLE_TTS_VOICE=en-US-Studio-O
GOOGLE_TTS_LANG=en-US
GOOGLE_STT_LANG=en-US
```

---

## Cost Comparison (per video, ~900 words)

### Before (OpenAI/Anthropic)
- Transcription: OpenAI Whisper - $0.006
- Summarization: Anthropic Claude - $0.015
- TTS: OpenAI tts-1-hd - $0.135
- **Total: ~$0.156 per video**

### After (Google Cloud/Gemini)
- Transcription: Google STT - $0.024
- Summarization: Gemini Flash - $0.001
- TTS: Google Cloud TTS - $0.072
- **Total: ~$0.097 per video**

**Savings: ~38% cheaper** (and better quality on TTS)

---

## Known Issues & Solutions

### 1. Large Audio Files (>10MB)
**Problem:** Google STT has 10MB inline limit  
**Solution:** Automatic GCS upload for large files, auto-cleanup after transcription

### 2. Long Video Timeouts
**Problem:** 30+ minute videos timeout at 10 minutes  
**Solution:** Increased timeout to 60 minutes (handles up to 2-hour videos)

### 3. yt-dlp JavaScript Runtime Warning
**Problem:** YouTube extraction warning about missing JS runtime  
**Solution:** Non-blocking warning, downloads still work. Can install `deno` if needed.

---

## Testing Commands

### Run Individual Stages
```bash
# Transcription
python -c "from src.transcription import transcribe_youtube_audio; transcribe_youtube_audio('https://youtube.com/...', 'projects/Test/0_transcript.txt')"

# Summarization
python -c "from src.summarization import summarize_transcript; summarize_transcript('projects/Test/0_transcript.txt', 'projects/Test/1_summary.txt')"

# TTS
python -c "from src.text_to_speech import synthesize_speech; synthesize_speech('projects/Test/1_summary.txt', 'projects/Test/2_audio.mp3')"

# Image Prompting
python -c "from src.image_prompting import generate_image_prompts; generate_image_prompts('projects/Test/1_summary.txt', 'projects/Test/2_audio.mp3', 'projects/Test/3_image_prompts.json')"

# Image Generation
python -c "from src.image_creation import create_images_from_prompts; create_images_from_prompts('projects/Test/3_image_prompts.json', 'projects/Test/5_images')"

# Metadata
python -c "from src.metadata_generation import generate_metadata; generate_metadata('projects/Test/1_summary.txt', 'projects/Test/4_metadata.json')"

# Video Composition
python -c "from src.video_composition import compose_video_from_assets; compose_video_from_assets('projects/Test/2_audio.mp3', 'projects/Test/5_images', 'projects/Test/6_final_video.mp4')"
```

### Run Unit Tests
```bash
pytest tests/unit/ -v
```

### Run Integration Tests (requires credentials)
```bash
pytest tests/integration/ -m integration -v
```

---

---

## 13:38 - CLI Pipeline Orchestrator Implemented

### Objective
Turn `main.py` into a fully usable end-to-end video generation tool. No more `python -c` commands.

### Changes Made

**Updated `main.py`:**
- Added imports for all pipeline modules
- Added `PIPELINE_STAGES` configuration (stages 0-6 with prerequisites)
- Added `get_stage_status()` - checks if output exists
- Added `print_pipeline_status()` - displays ✅/❌ for each stage
- Added `check_prerequisite()` - validates dependencies before running
- Added `confirm_overwrite()` - prompts before overwriting existing files
- Added `run_stage()` - executes individual pipeline stages with error handling
- Added `get_next_missing_stage()` - finds first incomplete stage
- Added `run_full_pipeline()` - runs all remaining stages automatically
- Added `pipeline_menu()` - new menu for pipeline control
- Updated `main_menu()` - added option 4 to access pipeline menu directly
- Auto-transitions to pipeline menu after transcription or script setup

### New CLI Flow

```
Main Menu:
1. Transcribe from YouTube URL → Pipeline Menu
2. Scrape from Article URL (coming soon)
3. Use a Ready-Made Script → Pipeline Menu
4. Go to Pipeline Menu
9. Exit

Pipeline Menu:
1. Run next missing step
2. Run full pipeline from current point
3. Run specific step (0-6)
4. Show project folder path
9. Back to main menu
```

### Pipeline Status Display
```
--- Pipeline Status ---
Project: MyVideo
Path: /home/user/projects/MyVideo
------------------------------
  0. 0_transcript.txt        ✅
  1. 1_summary.txt           ✅
  2. 2_audio.mp3             ❌
  3. 3_image_prompts.json    ❌
  4. 4_metadata.json         ❌
  5. 5_images/               ❌
  6. 6_final_video.mp4       ❌
------------------------------
```

### Features
- ✅ Prerequisite validation (won't run TTS without summary)
- ✅ Overwrite confirmation for existing outputs
- ✅ Error handling (returns to menu on failure)
- ✅ Auto-run TTS if image prompting needs audio duration
- ✅ Skip completed stages in full pipeline run
- ✅ Show project folder path helper

### Acceptance Criteria Met
- ✅ Create project from CLI
- ✅ Transcribe from YouTube without leaving CLI
- ✅ Drop ready-made script and continue
- ✅ Generate all stages (summary → audio → metadata → prompts → images → video)
- ✅ End with `6_final_video.mp4` created
- ✅ Never need `python -c` commands again

---

## 14:08 - Fix Inline Audio Duration Limit + Add Logging

### Problem 1: Inline Audio Duration Limit
8-minute video (9.7MB) failed with:
```
400 Inline audio exceeds duration limit. Please use a GCS URI.
```

**Root cause:** Google Cloud Speech-to-Text `long_running_recognize` has TWO limits:
- Size limit: 10MB for inline audio
- **Duration limit: ~1 minute for inline audio**

Even small files fail if they're longer than ~1 minute.

### Solution
Changed `src/transcription.py` to **always use GCS** for YouTube videos:
- Removed inline audio path entirely
- All audio now uploads to GCS before transcription
- This works for any duration (up to 480 minutes)

### Problem 2: No Logging
User requested simple logging to track CLI output for debugging.

### Solution
Created `src/logger.py`:
- Logs all console output to timestamped file
- Format: `logs/YYYYMMDD_HHMMSS_projectname.log`
- Each line prefixed with `[HH:MM:SS]` timestamp
- Auto-starts when project is created
- Shows log path in pipeline menu (option 4)

### Files Changed
- `src/transcription.py` - Always use GCS for long-running recognition
- `src/logger.py` - New logging utility
- `main.py` - Initialize logging on startup

### Log Output Example
```
=== Bibo Video Generator Log ===
Started: 2026-02-04 14:08:23
Project: MyVideo
========================================

[14:08:23] Project 'MyVideo' already exists. Using existing directory.
[14:08:25] -> Starting transcription for URL: https://...
[14:08:30] -> Downloading audio...
[14:08:45] -> Converting audio to FLAC...
[14:08:46]    - Audio file is 9.7MB
[14:08:46]    - Uploading to Google Cloud Storage...
...
```

---

## Next Session Goals
- [ ] Add progress bars for long operations
- [ ] Implement retry logic for transient API failures
- [ ] Add video preview/thumbnail generation
- [ ] Create web UI for pipeline management
- [ ] Add batch processing for multiple videos
- [ ] Optimize image generation (parallel processing)

---

## Documentation Created
- [x] README.md - Project overview and quick start
- [x] SETUP.md - Installation and configuration guide
- [x] ARCHITECTURE.md - Technical architecture and design
- [x] API.md - Module and function reference

---

## Notes
User confirmed end-to-end pipeline works using command-line execution. All Google Cloud services integrated and functional. Project ready for production use.
